{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import cv2\n",
    "import shutil\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some paths\n",
    "# Download images to a folder in this directory and set PATH variable to its path\n",
    "PATH = \"/Users/jeremystubbs/Desktop/Python/Machine_Learning_NNs/Mobilenet/mobilenet_custom/archive\"\n",
    "train_dir = os.path.join(PATH, 'train')\n",
    "validation_dir = os.path.join(PATH, 'valid')\n",
    "images_dir = os.path.join(PATH, \"images.csv\")\n",
    "\n",
    "if os.path.isdir(train_dir) is False:\n",
    "    os.mkdir(train_dir)\n",
    "if os.path.isdir(validation_dir) is False:\n",
    "    os.mkdir(validation_dir)\n",
    "\n",
    "# Create list of all unique labels from the csv file\n",
    "with open(images_dir) as f:\n",
    "    all_image_paths = [row.split(\",\")[0] for row in f]\n",
    "with open(images_dir) as f:\n",
    "    all_image_labels = [row.split(\",\")[2] for row in f] \n",
    "\n",
    "unique_labels = set(all_image_labels)\n",
    "\n",
    "# Make subfolders for each class\n",
    "for item in unique_labels:\n",
    "  if os.path.isdir('train/'+str(item)) is False:\n",
    "    os.mkdir('train/'+str(item))\n",
    "  if os.path.isdir('valid/'+str(item)) is False:\n",
    "    os.mkdir('valid/'+str(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undershirt\n",
      "94 24\n",
      "/Users/jeremystubbs/Desktop/Python/Machine_Learning_NNs/Mobilenet/mobilenet_custom/archive/images_originalf116a69b-3544-4ffd-8d7b-116def60fdab.jpg\n",
      "62384b64-25d5-4ed0-9fc2-d05c4af0b894\n",
      "label\n",
      "T-Shirt\n",
      "808 203\n",
      "/Users/jeremystubbs/Desktop/Python/Machine_Learning_NNs/Mobilenet/mobilenet_custom/archive/images_originala526cbda-d3c9-467a-8090-98ce0b28dcdd.jpg\n",
      "7fe4daa4-2802-42b4-8dee-68c114105a7a\n",
      "Other\n",
      "53 14\n",
      "/Users/jeremystubbs/Desktop/Python/Machine_Learning_NNs/Mobilenet/mobilenet_custom/archive/images_original6e69b257-4eaf-4785-95a9-f984ee195f20.jpg\n",
      "f88a9c13-fd71-42e6-9ea6-8b0597f1cce1\n",
      "Polo\n",
      "96 24\n",
      "/Users/jeremystubbs/Desktop/Python/Machine_Learning_NNs/Mobilenet/mobilenet_custom/archive/images_original7dd9bded-33f2-4928-b8f1-7efe0fd3bce3.jpg\n",
      "bdb96979-3a9a-4d64-98e6-bda684e7e81e\n",
      "Outwear\n",
      "249 63\n",
      "/Users/jeremystubbs/Desktop/Python/Machine_Learning_NNs/Mobilenet/mobilenet_custom/archive/images_original7183e0de-c9e1-45bf-9d89-9319afc727ec.jpg\n",
      "efbc5815-d1d4-4d85-8df2-9d9caae4300b\n",
      "Dress\n",
      "285 72\n",
      "/Users/jeremystubbs/Desktop/Python/Machine_Learning_NNs/Mobilenet/mobilenet_custom/archive/images_originalf246a9eb-ac60-4ed2-b815-e7887387a96a.jpg\n",
      "97cddbc9-a59f-490e-a10d-7878b2aff826\n",
      "Blazer\n",
      "87 22\n",
      "/Users/jeremystubbs/Desktop/Python/Machine_Learning_NNs/Mobilenet/mobilenet_custom/archive/images_original69b8ce1a-99eb-4e45-83bd-d95b2e04f2e5.jpg\n",
      "44640d54-24a3-4479-b33f-56bc476376da\n",
      "Shirt\n",
      "302 76\n",
      "/Users/jeremystubbs/Desktop/Python/Machine_Learning_NNs/Mobilenet/mobilenet_custom/archive/images_originalbfebe88b-33b9-44d0-851e-599f35a2ddd9.jpg\n",
      "ce367218-82f0-47ca-87cd-7b3bc173104c\n",
      "Skirt\n",
      "124 31\n",
      "/Users/jeremystubbs/Desktop/Python/Machine_Learning_NNs/Mobilenet/mobilenet_custom/archive/images_original567298c6-e892-4aa3-bac6-4f8993ee23c0.jpg\n",
      "1d08ddfe-dfd4-4bf9-81a7-9cc8dfa2833f\n",
      "Hoodie\n",
      "80 20\n",
      "/Users/jeremystubbs/Desktop/Python/Machine_Learning_NNs/Mobilenet/mobilenet_custom/archive/images_original3aa1b6a5-a2bf-42d9-a5e8-d53aa3bbd9b4.jpg\n",
      "b78fee17-fe42-4895-a4da-7b3aac0484ae\n",
      "Body\n",
      "55 14\n",
      "/Users/jeremystubbs/Desktop/Python/Machine_Learning_NNs/Mobilenet/mobilenet_custom/archive/images_original20d1b1f1-d416-439f-bedf-2eb453c6f0be.jpg\n",
      "39b8cb04-7495-49af-9910-27ce6e64a4c7\n",
      "Top\n",
      "34 9\n",
      "/Users/jeremystubbs/Desktop/Python/Machine_Learning_NNs/Mobilenet/mobilenet_custom/archive/images_original853039d6-d021-4caa-bd45-9756e0603a3c.jpg\n",
      "29d14f73-4983-4755-8efd-af82891267bc\n",
      "Blouse\n",
      "18 5\n",
      "/Users/jeremystubbs/Desktop/Python/Machine_Learning_NNs/Mobilenet/mobilenet_custom/archive/images_originaleca6677f-0ab4-46a1-9a3f-a4498d3d5a80.jpg\n",
      "4ef0dece-adfc-4036-ad34-922d607d4bd5\n",
      "Shorts\n",
      "246 62\n",
      "/Users/jeremystubbs/Desktop/Python/Machine_Learning_NNs/Mobilenet/mobilenet_custom/archive/images_original157f5e09-784d-45c8-a6bd-6029920ef0fd.jpg\n",
      "09c3cfd8-ee08-4253-8d7a-98c71b0b3566\n",
      "Pants\n",
      "553 139\n",
      "/Users/jeremystubbs/Desktop/Python/Machine_Learning_NNs/Mobilenet/mobilenet_custom/archive/images_originald7b371d1-0d06-4c06-9e51-70054e8dc72d.jpg\n",
      "ffd423dd-8b76-4a20-9561-b8cfc7a7b396\n",
      "Not sure\n",
      "182 46\n",
      "/Users/jeremystubbs/Desktop/Python/Machine_Learning_NNs/Mobilenet/mobilenet_custom/archive/images_originala92a4376-1c79-4fcc-a220-de33c580d680.jpg\n",
      "0426bbd2-0c53-46bd-b199-199b1f807cd1\n",
      "Longsleeve\n",
      "559 140\n",
      "/Users/jeremystubbs/Desktop/Python/Machine_Learning_NNs/Mobilenet/mobilenet_custom/archive/images_original7110460a-44eb-4bea-a477-e533a80f0db2.jpg\n",
      "2c050ddf-2681-4a03-9d0f-3b96b9cd5fe5\n",
      "Hat\n",
      "136 35\n",
      "/Users/jeremystubbs/Desktop/Python/Machine_Learning_NNs/Mobilenet/mobilenet_custom/archive/images_originala762dfc0-8da7-46d4-9ef1-3c7a085142da.jpg\n",
      "3d1948c4-067b-4f07-9310-7becd16dbd0f\n",
      "Shoes\n",
      "344 87\n",
      "/Users/jeremystubbs/Desktop/Python/Machine_Learning_NNs/Mobilenet/mobilenet_custom/archive/images_original5e3cd348-3f82-4b97-a7ba-25bedcdbbf7d.jpg\n",
      "927451d0-6fc4-4d19-b09f-2a30fe0e3628\n",
      "Skip\n",
      "9 3\n",
      "/Users/jeremystubbs/Desktop/Python/Machine_Learning_NNs/Mobilenet/mobilenet_custom/archive/images_original1d0129a1-f29a-4a3f-b103-f651176183eb.jpg\n",
      "a13897f4-75a7-491b-a813-4cb7472358a7\n"
     ]
    }
   ],
   "source": [
    "# Move all pictures to images_folder subfolders - change second part to your folder name\n",
    "IMAGES_PATH = os.path.join(PATH, 'images_original')\n",
    "for item in unique_labels:\n",
    "    # print(item)\n",
    "    temp_arr = []\n",
    "    if item == \"label\":\n",
    "        continue\n",
    "    for i in range(len(all_image_labels)):\n",
    "        if all_image_labels[i]==item:\n",
    "            temp_arr.append(all_image_paths[i])\n",
    "\n",
    "    k = int(len(temp_arr) * 0.8)\n",
    "    train_temp_arr = random.sample(temp_arr, k)  \n",
    "    valid_temp_arr = list(set(temp_arr).difference(train_temp_arr))\n",
    "    # print(len(train_temp_arr), len(valid_temp_arr))\n",
    "    # print(IMAGES_PATH+train_temp_arr[0]+\".jpg\")\n",
    "    # print(valid_temp_arr[0])\n",
    "\n",
    "    for val in train_temp_arr:\n",
    "        try:\n",
    "            shutil.copy(IMAGES_PATH +\"/\"+ val+\".jpg\", train_dir+\"/\"+item)\n",
    "        except:\n",
    "            x=2\n",
    "\n",
    "    for each in valid_temp_arr:\n",
    "        try:\n",
    "            shutil.copy(IMAGES_PATH +\"/\"+ each+\".jpg\", validation_dir+\"/\"+item)\n",
    "        except:\n",
    "            x=2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4314 files belonging to 21 classes.\n",
      "Found 1089 files belonging to 21 classes.\n"
     ]
    }
   ],
   "source": [
    "# Make training and validation Datasets\n",
    "BATCH_SIZE = 10\n",
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(train_dir,\n",
    "                                                            labels = \"inferred\",\n",
    "                                                            shuffle=True,\n",
    "                                                            batch_size=BATCH_SIZE,\n",
    "                                                            image_size=IMG_SIZE)\n",
    "\n",
    "validation_dataset = tf.keras.utils.image_dataset_from_directory(validation_dir,\n",
    "                                                                labels = \"inferred\",\n",
    "                                                                shuffle=True,\n",
    "                                                                batch_size=BATCH_SIZE,\n",
    "                                                                image_size=IMG_SIZE)\n",
    "\n",
    "class_names = train_dataset.class_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some images\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_dataset.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3714 images belonging to 13 classes.\n",
      "Found 935 images belonging to 13 classes.\n"
     ]
    }
   ],
   "source": [
    "# Define preprocessing function and create train and validation iterators\n",
    "\n",
    "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "\n",
    "# This does the same thing\n",
    "# rescale = tf.keras.layers.Rescaling(1./127.5, offset=-1)\n",
    "\n",
    "# Could include preprocessing here\n",
    "# train_dataset = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocess_input).flow_from_directory(directory=train_dir, target_size=(224,224), batch_size=10)\n",
    "# validation_dataset = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocess_input).flow_from_directory(directory=validation_dir,target_size=(224,224), batch_size=10)\n",
    "\n",
    "train_dataset = tf.keras.preprocessing.image.ImageDataGenerator().flow_from_directory(directory=train_dir, target_size=(224,224), batch_size=10)\n",
    "validation_dataset = tf.keras.preprocessing.image.ImageDataGenerator().flow_from_directory(directory=validation_dir,target_size=(224,224), batch_size=10)\n",
    "\n",
    "image_batch, label_batch = next(iter(train_dataset))\n",
    "# print(image_batch, label_batch)\n",
    "# print(type(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the base model from the pre-trained model MobileNet V2\n",
    "IMG_SHAPE = IMG_SIZE + (3,)\n",
    "\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "\n",
    "base_model2 = tf.keras.applications.MobileNetV2()\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "# Optional fine-tuning I read on tensorflow's official website\n",
    "# Let's take a look to see how many layers are in the base model\n",
    "# print(\"Number of layers in the base model: \", len(base_model.layers))\n",
    "\n",
    "# # Fine-tune from this layer onwards\n",
    "# fine_tune_at = 100\n",
    "\n",
    "# # Freeze all the layers before the `fine_tune_at` layer\n",
    "# for layer in base_model.layers[:fine_tune_at]:\n",
    "#   layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "##This cell creates the model\n",
    "# Add input, preprocessing, global average and prediction layer to the base model\n",
    "# feature_batch, and prediction_batch are optional \n",
    "# feature_batch = base_model(image_batch)\n",
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "# feature_batch_average = global_average_layer(feature_batch)\n",
    "# prediction_layer = tf.keras.layers.Dense(len(class_names),\n",
    "                        #   kernel_regularizer=tf.keras.regularizers.l2(0.0001))\n",
    "# prediction_batch = prediction_layer(feature_batch_average)\n",
    "prediction_layer = tf.keras.layers.Dense(units=13, activation='softmax')\n",
    "\n",
    "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "x = preprocess_input(inputs)\n",
    "x = base_model(x, training=False)\n",
    "x = global_average_layer(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "outputs = prediction_layer(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Here is an alternative setup\n",
    "# model.compile(\n",
    "#   optimizer=tf.keras.optimizers.SGD(learning_rate=0.005, momentum=0.9), \n",
    "#   loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.1),\n",
    "#   metrics=['accuracy'])\n",
    "\n",
    "# model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "372/372 [==============================] - 282s 756ms/step - loss: 1.0827 - accuracy: 0.6605 - val_loss: 0.6938 - val_accuracy: 0.7775\n",
      "Epoch 2/10\n",
      "372/372 [==============================] - 280s 752ms/step - loss: 0.5960 - accuracy: 0.8094 - val_loss: 0.5787 - val_accuracy: 0.7979\n",
      "Epoch 3/10\n",
      "372/372 [==============================] - 281s 754ms/step - loss: 0.4780 - accuracy: 0.8446 - val_loss: 0.5590 - val_accuracy: 0.8150\n",
      "Epoch 4/10\n",
      "372/372 [==============================] - 279s 750ms/step - loss: 0.4081 - accuracy: 0.8654 - val_loss: 0.5450 - val_accuracy: 0.8118\n",
      "Epoch 5/10\n",
      "372/372 [==============================] - 279s 750ms/step - loss: 0.3650 - accuracy: 0.8732 - val_loss: 0.5498 - val_accuracy: 0.8139\n",
      "Epoch 6/10\n",
      "372/372 [==============================] - 279s 750ms/step - loss: 0.3212 - accuracy: 0.8880 - val_loss: 0.5989 - val_accuracy: 0.8032\n",
      "Epoch 7/10\n",
      "372/372 [==============================] - 282s 757ms/step - loss: 0.2953 - accuracy: 0.8998 - val_loss: 0.5827 - val_accuracy: 0.8021\n",
      "Epoch 8/10\n",
      "372/372 [==============================] - 281s 754ms/step - loss: 0.2680 - accuracy: 0.9114 - val_loss: 0.5489 - val_accuracy: 0.8193\n",
      "Epoch 9/10\n",
      "372/372 [==============================] - 278s 747ms/step - loss: 0.2479 - accuracy: 0.9211 - val_loss: 0.6000 - val_accuracy: 0.8043\n",
      "Epoch 10/10\n",
      "372/372 [==============================] - 288s 773ms/step - loss: 0.2228 - accuracy: 0.9289 - val_loss: 0.5880 - val_accuracy: 0.8064\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1468a3910>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model\n",
    "initial_epochs = 10\n",
    "\n",
    "model.fit(train_dataset,\n",
    "                    epochs=initial_epochs, \n",
    "                    validation_data=validation_dataset, )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.6554790e-07 9.7837526e-01 7.6489923e-05 1.4933976e-03 6.4658729e-04\n",
      "  8.7753988e-06 4.0986665e-04 1.8605724e-02 1.2913530e-04 1.3564948e-04\n",
      "  1.4675536e-05 8.2458348e-05 2.1192469e-05]]\n"
     ]
    }
   ],
   "source": [
    "## Predict images in test set with model \n",
    "img = cv2.imread(\"dress2.jpg\")\n",
    "resized = cv2.resize(img, (224, 224))\n",
    "reshaped = resized.reshape(1, 224, 224, 3)\n",
    "# print(type(reshaped), reshaped.shape)\n",
    "\n",
    "\n",
    "predictions = model.predict(reshaped, verbose=0)\n",
    "print(predictions)\n",
    "# Note: the label map is ['Blazer','Dress','Hat','Hoodie', 'Longsleeve','Pants', 'Polo','Shirt','Shoes','Shorts', 'Skirt','T-Shirt','Undershirt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Save model\n",
    "os.chdir(\"/Users/jeremystubbs/Desktop/Python/Machine_Learning_NNs/Mobilenet/mobilenet_custom/\")\n",
    "!mkdir -p saved_model\n",
    "model.save('saved_model/my_model')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "52ee2977380704a66854748a73250e0671a9318bd5b3fd45a3df9f851ae61629"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
